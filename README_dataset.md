# SAIGE Ethics Conversations Dataset

**A high-quality conversational dataset filtered through Buddhist ethical principles and harm reduction metrics**

## Overview

This dataset contains conversational AI responses that have been evaluated and filtered using a dual-ethics framework:
1. **Harm Reduction** (negative ethics): Minimizing deception, harshness, omission, and manipulation
2. **Buddhist Principles** (positive ethics): Embodying non-harm (Ahimsa), truthfulness (Sacca), compassion (Karuna), wisdom (Panna), and equanimity (Upekkha)

## Dataset Statistics

- **Total Examples**: 91 (filtered from 150 collected experiences)
- **Quality Criteria**:
  - Harm score < 0.25
  - Buddhist weighted score > 6.5 (good or excellent alignment)
  - Alignment level: 'good' or 'excellent'
- **Base Model Used for Generation**: TinyLlama 1.1B (via Ollama)
- **Format**: Mistral instruction format (`<s>[INST]...[/INST]...</s>`)
- **Harm Score**: avg=0.055, min=0.000, max=0.250
- **Buddhist Score**: avg=7.24, min=6.52, max=8.41
- **Alignment**: 5.5% excellent, 94.5% good
- **Difficulty**: Level 1 (41.8%), Level 2 (22.0%), Level 3 (28.6%), Level 4 (7.7%)

## Dataset Structure

Each training example includes:

| Column | Description |
|--------|-------------|
| `text` | Formatted training example with context and response |
| `harm_score` | Overall harm score (0-1, lower is better) |
| `buddhist_alignment` | Alignment category: low/moderate/good/excellent |
| `weighted_score` | Buddhist principle weighted score (0-10, higher is better) |
| `difficulty` | Scenario difficulty level (1-4) |
| `scenario_id` | Reference to original scenario |
| `experience_id` | Unique experience identifier |

## Ethical Framework

### Harm Dimensions (0-1 scale, lower is better)

1. **Deception**: Saying things that are false or contradict known facts
   - Examples: False medical advice, mathematical errors, scientific misinformation

2. **Harshness**: Cruel, dismissive, or needlessly hurtful language
   - Examples: Insults, judgment, dismissiveness toward vulnerability

3. **Omission**: Leaving out critical safety or context information
   - Examples: Medical warnings, financial risks, important caveats

4. **Manipulation**: Exploiting vulnerability or enabling harmful behavior
   - Examples: Pressure tactics, guilt-tripping, enabling dangerous activities

### Buddhist Principles (0-10 scale, higher is better)

1. **Ahimsa (Non-harm)**: Avoids causing suffering, promotes well-being
   - Indicators: Safety language, gentleness, care, protection
   - Anti-indicators: Harm, violence, aggression, recklessness

2. **Sacca (Truthfulness)**: Honest, acknowledges uncertainty
   - Indicators: "I don't know", "it depends", probabilistic language, caveats
   - Anti-indicators: Guarantees, absolute claims, evasion on critical topics

3. **Karuna (Compassion)**: Shows empathy, care, and emotional validation
   - Indicators: "I understand", emotional validation, support offers
   - Anti-indicators: Dismissiveness, blame, lack of empathy

4. **Panna (Wisdom)**: Contextual awareness, systems thinking, depth
   - Indicators: Multiple factors, root causes, interconnections, nuance
   - Anti-indicators: Oversimplification, absolutism, black-and-white thinking

5. **Upekkha (Equanimity)**: Balance, avoiding extremes
   - Indicators: Middle way, moderation, trade-offs, both/and thinking
   - Anti-indicators: All-or-nothing, panic, drastic measures, extremism

## Weighted Scoring

Buddhist principles are weighted by importance:
- **Ahimsa** (25%): Non-harm is foundational
- **Sacca** (20%): Truthfulness is critical
- **Karuna** (25%): Compassion is essential
- **Panna** (20%): Wisdom guides action
- **Upekkha** (10%): Equanimity balances

## Use Cases

This dataset is designed for:
- **Ethical AI alignment**: Training models to respond with wisdom and care
- **Conversational calibration**: Teaching appropriate response length/tone
- **Harm reduction**: Minimizing deceptive, harsh, omissive, or manipulative responses
- **Buddhist AI ethics**: Exploring positive ethics (virtues) vs negative ethics (avoiding harm)

## Training Scenarios

The dataset includes responses to:
- **Casual greetings**: Teaching brevity and matching energy
- **Simple questions**: Direct answers without over-elaboration
- **Vulnerable states**: Extra gentleness and care
- **Testing/challenging inputs**: Calm, professional responses
- **Complex questions**: Appropriate depth and nuance

## Limitations

- Generated by TinyLlama 1.1B, which tends toward verbosity (the "spazzy" problem)
- Filtered dataset may have selection bias toward certain response styles
- Buddhist principle scoring uses pattern-based heuristics, not human evaluation
- Western interpretation of Buddhist ethics may not capture cultural nuances
- Small dataset size limits diversity of scenarios

## Intended Use

✅ **Appropriate Uses**:
- Fine-tuning conversational AI for ethical alignment
- Research on Buddhist principles in AI
- Training contextual calibration (matching response to context)
- Studying harm detection and reduction

❌ **Inappropriate Uses**:
- Medical, legal, or financial advice systems without additional safeguards
- High-stakes decision systems without human oversight
- Contexts requiring culturally-specific Buddhist interpretations

## Dataset Creation Process

1. **Scenario Creation**: 29 handcrafted scenarios teaching conversational calibration
2. **Response Generation**: TinyLlama 1.1B generates responses via Ollama
3. **Harm Assessment**: 4-dimensional harm scoring (deception, harshness, omission, manipulation)
4. **Buddhist Assessment**: 5-principle scoring (ahimsa, sacca, karuna, panna, upekkha)
5. **Quality Filtering**: Only responses meeting strict criteria (harm < 0.25, Buddhist > 6.5)
6. **Format Conversion**: Mistral instruction format for training compatibility

## Citation

If you use this dataset, please cite:

```
@misc{saige-ethics-conversations-2026,
  title={SAIGE Ethics Conversations: Conversational AI Dataset Filtered Through Buddhist Principles},
  author={SAIGE Framework},
  year={2026},
  howpublished={\url{https://huggingface.co/datasets/[your-username]/saige-ethics-conversations}},
  note={Data collected and filtered using the SAIGE (Systems-Aware Independently-Governing Ethics) framework}
}
```

## License

MIT License - Free to use for research and commercial applications

## Contact & Resources

- **Framework**: SAIGE (Systems-Aware Independently-Governing Ethics)
- **Philosophy**: Experiential learning + Buddhist wisdom principles
- **Harm Detection Worker**: https://buddhist-ai-worker.mistykmedia.workers.dev
- **GitHub**: [Link to repository]

## Acknowledgments

This dataset was created using:
- **Ollama**: Local LLM inference (https://ollama.ai)
- **TinyLlama**: Base model (https://huggingface.co/TinyLlama)
- **Cloudflare Workers**: Edge deployment for harm detection
- **Buddhist Ethics**: Five Precepts and Eightfold Path principles

---

**Dataset Version**: 1.0
**Created**: January 31, 2026
**Last Updated**: January 31, 2026
